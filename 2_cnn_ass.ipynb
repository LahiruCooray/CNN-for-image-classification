{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfAjQCGspFcH6yNvCWlCRq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nipuni1313/CNN-for-image-classification/blob/main/2_cnn_ass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2j5Dn_UV-2vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "IMG_SIZE = 224  # Image size for ResNet50 and VGG16\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "NUM_CLASSES = 6  # Update this based on your dataset\n",
        "DATASET_PATH = '/content/drive/MyDrive/RealWasteDataset_D/'"
      ],
      "metadata": {
        "id": "wEzzCkWP-4pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Split dataset into training, validation, and testing\n",
        "train_dir = os.path.join(DATASET_PATH, 'train')\n",
        "val_dir = os.path.join(DATASET_PATH, 'validation')\n",
        "test_dir = os.path.join(DATASET_PATH, 'test')\n",
        "\n",
        "# Step 2: Data Generators for Augmentation and Preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='categorical'\n",
        ")\n",
        "val_data = val_test_datagen.flow_from_directory(\n",
        "    val_dir, target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='categorical'\n",
        ")\n",
        "test_data = val_test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "RUVwojiY-8Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dEY6TAz-eOW"
      },
      "outputs": [],
      "source": [
        "# Step 3: Model Creation Function\n",
        "def build_model(base_model, num_classes, dropout_rate=0.2, trainable_layers=0):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    base_model.trainable = False  # Freeze the base model initially\n",
        "\n",
        "    # Custom Top Layers\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name=f\"{base_model.name}_FineTuned\")\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Step 4: Train and Evaluate Models\n",
        "def train_and_evaluate(model, train_data, val_data, test_data, epochs, model_name):\n",
        "    history = model.fit(train_data, validation_data=val_data, epochs=epochs)\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_data)\n",
        "    print(f\"{model_name} Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "    return history, test_acc\n",
        "\n",
        "# Step 5: Plot Training History\n",
        "def plot_history(histories, test_accuracies, model_names):\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    for history, test_acc, name in zip(histories, test_accuracies, model_names):\n",
        "        plt.plot(history.history['accuracy'], label=f'{name} Train Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label=f'{name} Validation Accuracy')\n",
        "        plt.axhline(y=test_acc, linestyle='--', label=f'{name} Test Accuracy')\n",
        "\n",
        "    plt.title(\"Training, Validation, and Test Accuracies\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Step 6: Fine-Tune Models\n",
        "def fine_tune_model(model, unfreeze_layers, train_data, val_data, test_data, epochs):\n",
        "    # Unfreeze the top layers for fine-tuning\n",
        "    for layer in model.layers[-unfreeze_layers:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    history = model.fit(train_data, validation_data=val_data, epochs=epochs)\n",
        "    test_loss, test_acc = model.evaluate(test_data)\n",
        "    print(f\"Fine-Tuned Test Accuracy: {test_acc:.2f}\")\n",
        "    return history, test_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Main Execution\n",
        "base_resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling='avg')\n",
        "base_vgg = VGG16(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling='avg')\n",
        "\n",
        "# Initialize models\n",
        "resnet_model = build_model(base_resnet, NUM_CLASSES)\n",
        "vgg_model = build_model(base_vgg, NUM_CLASSES)"
      ],
      "metadata": {
        "id": "aPiB0Iaz_JkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train resnet\n",
        "history_resnet, resnet_test_acc = train_and_evaluate(resnet_model, train_data, val_data, test_data, EPOCHS, \"ResNet50\")"
      ],
      "metadata": {
        "id": "zK4p3RD3_LXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train vgg\n",
        "history_vgg, vgg_test_acc = train_and_evaluate(vgg_model, train_data, val_data, test_data, EPOCHS, \"VGG16\")"
      ],
      "metadata": {
        "id": "Q3x5L-zt_2vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune models\n",
        "history_resnet_fine, resnet_test_acc_fine = fine_tune_model(resnet_model, unfreeze_layers=20, train_data=train_data, val_data=val_data, test_data=test_data, epochs=5)"
      ],
      "metadata": {
        "id": "xXwVbvoMAA5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune models\n",
        "history_vgg_fine, vgg_test_acc_fine = fine_tune_model(vgg_model, unfreeze_layers=20, train_data=train_data, val_data=val_data, test_data=test_data, epochs=5)\n"
      ],
      "metadata": {
        "id": "1Ev0LavmABpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histories\n",
        "plot_history(\n",
        "    [history_resnet, history_resnet_fine, history_vgg, history_vgg_fine],\n",
        "    [resnet_test_acc_fine, vgg_test_acc_fine],\n",
        "    [\"ResNet50\", \"ResNet50 (Fine-Tuned)\", \"VGG16\", \"VGG16 (Fine-Tuned)\"]\n",
        ")"
      ],
      "metadata": {
        "id": "LyqKUNBP_GKl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}