{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN+JIMdeZZQhKfQY1OTAvtA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nipuni1313/CNN-for-image-classification/blob/main/2_SOTA_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBpEaeBe2Goh",
        "outputId": "538c9bdb-5dc9-469b-e83d-ddd9e20e4cbb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train, val, and test directories\n",
        "train_dir = '/content/drive/MyDrive/RealWasteDataset_D/train/'\n",
        "val_dir = '/content/drive/MyDrive/RealWasteDataset_D/validation/'\n",
        "test_dir = '/content/drive/MyDrive/RealWasteDataset_D/test/'\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path to your image dataset\n",
        "dataset_path = '/content/drive/MyDrive/RealWaste_D/'\n",
        "\n",
        "# List all categories (assumes subfolders for each category)\n",
        "categories = os.listdir(dataset_path)\n",
        "\n",
        "\n",
        "\n",
        "for dir in [train_dir, val_dir, test_dir]:\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "# Create directories for each category inside train, val, and test\n",
        "for category in categories:\n",
        "    os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, category), exist_ok=True)\n"
      ],
      "metadata": {
        "id": "5p5uS_Rc2IN5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train, validation, and test sets\n",
        "for category in categories:\n",
        "    category_path = os.path.join('/content/drive/MyDrive/RealWaste_D/', category)\n",
        "\n",
        "    # Check if the category path exists and is a directory\n",
        "    if os.path.isdir(category_path) and len(os.listdir(category_path)) > 0:\n",
        "        images = os.listdir(category_path)\n",
        "\n",
        "        # Split the data into 60% train, 20% validation, 20% test\n",
        "        train_images, temp_images = train_test_split(images, test_size=0.4, random_state=42)\n",
        "        val_images, test_images = train_test_split(temp_images, test_size=0.5, random_state=42)\n",
        "\n",
        "        # Create target category directories in train, val, and test directories if they don't exist\n",
        "        os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, category), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_dir, category), exist_ok=True)\n",
        "\n",
        "        # Move files to respective directories\n",
        "        for image in train_images:\n",
        "            # Check if the image is already in the target directory\n",
        "            target_path = os.path.join(train_dir, category, image)\n",
        "            if not os.path.exists(target_path):  # Only move if the image doesn't exist\n",
        "                shutil.move(os.path.join(category_path, image), target_path)\n",
        "\n",
        "        for image in val_images:\n",
        "            # Check if the image is already in the target directory\n",
        "            target_path = os.path.join(val_dir, category, image)\n",
        "            if not os.path.exists(target_path):  # Only move if the image doesn't exist\n",
        "                shutil.move(os.path.join(category_path, image), target_path)\n",
        "\n",
        "        for image in test_images:\n",
        "            # Check if the image is already in the target directory\n",
        "            target_path = os.path.join(test_dir, category, image)\n",
        "            if not os.path.exists(target_path):  # Only move if the image doesn't exist\n",
        "                shutil.move(os.path.join(category_path, image), target_path)\n",
        "\n",
        "print(\"Dataset split into train, validation, and test directories.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRt595jy2uXc",
        "outputId": "0f53e3ab-6dc4-4784-da97-03f7c5d78953"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split into train, validation, and test directories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Initialize ImageDataGenerator for data augmentation (train only)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,        # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,     # Random rotations\n",
        "    width_shift_range=0.2, # Random horizontal shift\n",
        "    height_shift_range=0.2, # Random vertical shift\n",
        "    shear_range=0.2,       # Shear transformation\n",
        "    zoom_range=0.2,        # Random zoom\n",
        "    horizontal_flip=True,  # Random horizontal flip\n",
        "    fill_mode='nearest'    # Fill empty pixels\n",
        ")\n",
        "\n",
        "# For validation and test, we just rescale the images\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load data using flow_from_directory\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,  # Directory with training data\n",
        "    target_size=(256, 256),    # Resize images\n",
        "    batch_size=32,\n",
        "    class_mode='sparse'  # Set to 'sparse' to get integer labels\n",
        ")\n",
        "\n",
        "val_data = val_test_datagen.flow_from_directory(\n",
        "    val_dir,  # Directory with validation data\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse'  # Set to 'sparse' to get integer labels\n",
        ")\n",
        "\n",
        "test_data = val_test_datagen.flow_from_directory(\n",
        "    test_dir,  # Directory with test data\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse'  # Set to 'sparse' to get integer labels\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB8qrutj28kr",
        "outputId": "a10f6ac5-b711-4f3e-b751-f28c37f495de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2902 images belonging to 9 classes.\n",
            "Found 968 images belonging to 9 classes.\n",
            "Found 972 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "jpg72wT13Cio"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet50"
      ],
      "metadata": {
        "id": "gFGL_91g5BPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in resnet_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top\n",
        "resnet_model = Sequential([\n",
        "    resnet_base,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_data.class_indices), activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "resnet_model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "T9h-V5sz49vu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_resnet = resnet_model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=20,  # Set the number of epochs as needed\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_steps=len(val_data)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScU9ntha5AoH",
        "outputId": "9bad1e10-07f5-49a5-ac82-85b2652d5abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - accuracy: 0.1202 - loss: 2.6684 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_data, steps=len(test_data))\n",
        "print(f\"ResNet50 Test Accuracy: {resnet_test_acc}\")"
      ],
      "metadata": {
        "id": "IqmyKu5S5Lo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG16"
      ],
      "metadata": {
        "id": "NUqXIr925XJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in vgg_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top\n",
        "vgg_model = Sequential([\n",
        "    vgg_base,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_data.class_indices), activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "vgg_model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tYmC0k485YtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_vgg = vgg_model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=20,  # Set the number of epochs as needed\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_steps=len(val_data)\n",
        ")\n"
      ],
      "metadata": {
        "id": "XFT1VLEP5_AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_data, steps=len(test_data))\n",
        "print(f\"VGG16 Test Accuracy: {vgg_test_acc}\")\n"
      ],
      "metadata": {
        "id": "MBGnkvz46B1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the training results"
      ],
      "metadata": {
        "id": "7xJrbGb86GYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history, model_name):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'{model_name} Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{model_name} Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_resnet, \"ResNet50\")\n",
        "plot_history(history_vgg, \"VGG16\")\n"
      ],
      "metadata": {
        "id": "XQuxqeJL6FUz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}