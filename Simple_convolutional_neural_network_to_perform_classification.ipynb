{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nipuni1313/CNN-for-image-classification/blob/main/Simple_convolutional_neural_network_to_perform_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXk-KSKaf2oi",
        "outputId": "26d796ac-d999-4911-d3ca-ecd568f2564e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "M0xJGQPCqrPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/RealWaste/'\n",
        "output_path = '/content/drive/MyDrive/RealWaste_output/'\n",
        "files = os.listdir(dataset_path)\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLX_vTHLqRdL",
        "outputId": "7d6f906f-c7b1-4d71-e900-8e6891c70957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Vegetation', 'Textile Trash', 'Plastic', 'Paper', 'Miscellaneous Trash', 'Metal', 'Glass', 'Food Organics', 'Cardboard', 'RealWaste output']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install Augmentor tensorflow opencv-python\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import Augmentor\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import img_to_array, array_to_img\n",
        "from tensorflow.image import resize\n",
        "from PIL import Image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H_3BPhbTxW-C",
        "outputId": "0a695e65-5487-4a51-d87b-fad678da45ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Augmentor in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (11.0.0)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (4.66.6)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess image (resize and normalize)\n",
        "def preprocess_image(img_path, target_size=(128, 128)):\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize(target_size)\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "# Function for data augmentation\n",
        "def augment_data(input_directory, augmented_directory, num_augmented_images=5):\n",
        "    \"\"\"\n",
        "    Perform data augmentation for each class in the dataset, and save to a separate augmented directory.\n",
        "    The original data is copied to the augmented directory first, then augmentation is applied.\n",
        "    \"\"\"\n",
        "    for class_folder in os.listdir(input_directory):\n",
        "        class_path = os.path.join(input_directory, class_folder)\n",
        "\n",
        "        if os.path.isdir(class_path):\n",
        "            print(f\"Processing class: {class_folder}...\")\n",
        "\n",
        "            # Create the same class folder in the augmented dataset if it doesn't exist\n",
        "            augmented_class_folder = os.path.join(augmented_directory, class_folder)\n",
        "            os.makedirs(augmented_class_folder, exist_ok=True)\n",
        "\n",
        "            # Check if originals are already copied, if not, copy and preprocess them\n",
        "            original_images_in_augmented = os.listdir(augmented_class_folder)\n",
        "            if not original_images_in_augmented:  # Only copy if folder is empty\n",
        "                for image_file in os.listdir(class_path):\n",
        "                    if image_file.endswith(('jpg', 'jpeg', 'png')):\n",
        "                        original_image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "                        # Preprocess and normalize original images\n",
        "                        original_img = preprocess_image(original_image_path)\n",
        "\n",
        "                        # Save the preprocessed original image in the augmented folder\n",
        "                        img_name = image_file.split('.')[0] + \"_original.jpg\"\n",
        "                        save_path = os.path.join(augmented_class_folder, img_name)\n",
        "                        original_img = array_to_img(original_img)  # Convert back to image for saving\n",
        "                        original_img.save(save_path)\n",
        "            # Create Augmentor pipeline for this class folder\n",
        "            pipeline = Augmentor.Pipeline(class_path)\n",
        "            pipeline.rotate(probability=0.7, max_left_rotation=15, max_right_rotation=15)\n",
        "            pipeline.flip_left_right(probability=0.5)\n",
        "            pipeline.flip_top_bottom(probability=0.5)\n",
        "            pipeline.zoom_random(probability=0.5, percentage_area=0.8)\n",
        "            pipeline.random_contrast(probability=0.5, min_factor=0.7, max_factor=1.3)\n",
        "            pipeline.random_brightness(probability=0.5, min_factor=0.7, max_factor=1.3)\n",
        "\n",
        "            # Augment and save images to the augmented dataset folder\n",
        "            pipeline.sample(num_augmented_images)\n",
        "\n",
        "            # Move augmented images into the augmented folder\n",
        "            augmented_folder = os.path.join(class_path, \"output\")  # Augmentor stores images here\n",
        "            for augmented_image in os.listdir(augmented_folder):\n",
        "                img_path = os.path.join(augmented_folder, augmented_image)\n",
        "                if augmented_image.endswith(('jpg', 'jpeg', 'png')):\n",
        "                    augmented_img = preprocess_image(img_path)\n",
        "                    img_name = augmented_image.split('.')[0] + \"_augmented.jpg\"\n",
        "                    save_path = os.path.join(augmented_class_folder, img_name)  # Save in augmented folder\n",
        "                    augmented_img = array_to_img(augmented_img)\n",
        "                    augmented_img.save(save_path)\n",
        "\n",
        "\n",
        "# Function to split dataset into training, validation, and testing sets (by class)\n",
        "def split_dataset(input_directory, output_directory, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Split the augmented dataset into training, validation, and testing sets for each class folder.\n",
        "    \"\"\"\n",
        "    # Loop through each class folder in the augmented dataset\n",
        "    for class_folder in os.listdir(input_directory):\n",
        "        class_path = os.path.join(input_directory, class_folder)\n",
        "\n",
        "        if os.path.isdir(class_path):\n",
        "            print(f\"Splitting {class_folder} images into train, val, and test sets...\")\n",
        "\n",
        "            # List all the images in the current class folder\n",
        "            image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "            random.shuffle(image_files)\n",
        "\n",
        "            total_images = len(image_files)\n",
        "            train_size = int(total_images * train_ratio)\n",
        "            val_size = int(total_images * val_ratio)\n",
        "            test_size = total_images - train_size - val_size\n",
        "\n",
        "            train_files = image_files[:train_size]\n",
        "            val_files = image_files[train_size:train_size + val_size]\n",
        "            test_files = image_files[train_size + val_size:]\n",
        "\n",
        "            # Create directories for each subset (train, val, test) within the class folder\n",
        "            class_train_dir = os.path.join(output_directory, 'train', class_folder)\n",
        "            class_val_dir = os.path.join(output_directory, 'val', class_folder)\n",
        "            class_test_dir = os.path.join(output_directory, 'test', class_folder)\n",
        "\n",
        "            os.makedirs(class_train_dir, exist_ok=True)\n",
        "            os.makedirs(class_val_dir, exist_ok=True)\n",
        "            os.makedirs(class_test_dir, exist_ok=True)\n",
        "\n",
        "            # Move images to the respective directories\n",
        "            for image in train_files:\n",
        "                shutil.copy(os.path.join(class_path, image), os.path.join(class_train_dir, image))\n",
        "\n",
        "            for image in val_files:\n",
        "                shutil.copy(os.path.join(class_path, image), os.path.join(class_val_dir, image))\n",
        "\n",
        "            for image in test_files:\n",
        "                shutil.copy(os.path.join(class_path, image), os.path.join(class_test_dir, image))\n",
        "\n",
        "            print(f\"Dataset split complete for {class_folder}: {train_size} training, {val_size} validation, {test_size} test images.\")\n"
      ],
      "metadata": {
        "id": "LwOJ6bLUxSea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Path to the RealWASTE dataset\n",
        "input_directory = dataset_path  # Path to your original RealWASTE dataset images\n",
        "\n",
        "# Path to save augmented and split images\n",
        "output_directory =  output_path # Path where the processed data will be saved\n",
        "\n"
      ],
      "metadata": {
        "id": "_y1Ue2KJx6uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Perform data augmentation\n",
        "augment_data(input_directory, output_directory, num_augmented_images=5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg_y5iIlylFe",
        "outputId": "c5b4a69c-e402-4882-9286-066a005433cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Vegetation...\n",
            "Initialised with 436 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/RealWaste/Vegetation/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=524x524 at 0x7C8DC1B67F70>: 100%|██████████| 5/5 [00:00<00:00, 24.73 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Textile Trash...\n",
            "Initialised with 318 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/RealWaste/Textile Trash/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=524x524 at 0x7C8DC1B7C580>: 100%|██████████| 5/5 [00:00<00:00, 18.22 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Plastic...\n",
            "Initialised with 921 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/RealWaste/Plastic/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=524x524 at 0x7C8DC1B65F00>: 100%|██████████| 5/5 [00:00<00:00, 16.90 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Paper...\n",
            "Initialised with 500 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/RealWaste/Paper/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=524x524 at 0x7C8DC1B7CFD0>: 100%|██████████| 5/5 [00:00<00:00, 22.24 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Miscellaneous Trash...\n",
            "Initialised with 495 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/RealWaste/Miscellaneous Trash/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=524x524 at 0x7C8DC1B657E0>: 100%|██████████| 5/5 [00:00<00:00, 21.60 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Metal...\n",
            "Initialised with 790 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/RealWaste/Metal/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=524x524 at 0x7C8DC1B64CA0>: 100%|██████████| 5/5 [00:00<00:00, 30.29 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Glass...\n",
            "Initialised with 420 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/RealWaste/Glass/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=524x524 at 0x7C8DC1B67A00>: 100%|██████████| 5/5 [00:00<00:00, 24.85 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Food Organics...\n",
            "Initialised with 411 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/RealWaste/Food Organics/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=524x524 at 0x7C8DC1B64D90>: 100%|██████████| 5/5 [00:00<00:00, 19.70 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing class: Cardboard...\n",
            "Initialised with 461 image(s) found.\n",
            "Output directory set to /content/drive/MyDrive/RealWaste/Cardboard/output."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=524x524 at 0x7C8DC1B677F0>: 100%|██████████| 5/5 [00:00<00:00, 16.20 Samples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Split the dataset into training, validation, and testing sets\n",
        "split_dataset(output_directory, output_directory, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXqRTOAW8Sxr",
        "outputId": "04288c28-6d7e-4856-b046-72af7e9be73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting Vegetation images into train, val, and test sets...\n",
            "Dataset split complete for Vegetation: 267 training, 89 validation, 90 test images.\n",
            "Splitting Textile Trash images into train, val, and test sets...\n",
            "Dataset split complete for Textile Trash: 196 training, 65 validation, 67 test images.\n",
            "Splitting Plastic images into train, val, and test sets...\n",
            "Dataset split complete for Plastic: 558 training, 186 validation, 187 test images.\n",
            "Splitting Paper images into train, val, and test sets...\n",
            "Dataset split complete for Paper: 306 training, 102 validation, 102 test images.\n",
            "Splitting Miscellaneous Trash images into train, val, and test sets...\n",
            "Dataset split complete for Miscellaneous Trash: 303 training, 101 validation, 101 test images.\n",
            "Splitting Metal images into train, val, and test sets...\n",
            "Dataset split complete for Metal: 480 training, 160 validation, 160 test images.\n",
            "Splitting Glass images into train, val, and test sets...\n",
            "Dataset split complete for Glass: 258 training, 86 validation, 86 test images.\n",
            "Splitting Food Organics images into train, val, and test sets...\n",
            "Dataset split complete for Food Organics: 252 training, 84 validation, 85 test images.\n",
            "Splitting Cardboard images into train, val, and test sets...\n",
            "Dataset split complete for Cardboard: 282 training, 94 validation, 95 test images.\n"
          ]
        }
      ]
    }
  ]
}